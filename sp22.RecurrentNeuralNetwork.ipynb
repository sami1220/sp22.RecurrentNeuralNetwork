{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sprint22 リカレントニューラルネットワーク"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 【問題1】SimpleRNNのフォワードプロパゲーション実装\n",
    "\n",
    "SimpleRNNのクラスSimpleRNNを作成してください。基本構造はFCクラスと同じになります。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。\n",
    "\n",
    "ndarrayのshapeがどうなるかを併記しています。\n",
    "\n",
    "バッチサイズをbatch_size、入力の特徴量数をn_features、RNNのノード数をn_nodesとして表記します。\n",
    "\n",
    "活性化関数はtanhとして進めますが、これまでのニューラルネットワーク同様にReLUなどに置き換えられます。\n",
    "\n",
    "$a_t = x_{t}\\cdot W_{x} + h_{t-1}\\cdot W_{h} + B\\\\$\n",
    "$h_t = tanh(a_t)$\n",
    "\n",
    "$at$ : 時刻tの活性化関数を通す前の状態 (batch_size, n_nodes)\n",
    "\n",
    "\n",
    "$ht$ : 時刻tの状態・出力 (batch_size, n_nodes)\n",
    "\n",
    "\n",
    "$xt$ : 時刻tの入力 (batch_size, n_features)\n",
    "\n",
    "\n",
    "$Wx$ : 入力に対する重み (n_features, n_nodes)\n",
    "\n",
    "\n",
    "$ht−1$ : 時刻t-1の状態（前の時刻から伝わる順伝播） (batch_size, n_nodes)\n",
    "\n",
    "\n",
    "$Wh$ : 状態に対する重み。 (n_nodes, n_nodes)\n",
    "\n",
    "\n",
    "$B$: バイアス項 (n_nodes,)\n",
    "\n",
    "\n",
    "初期状態 $h0$はすべて0とすることが多いですが、任意の値を与えることも可能です。\n",
    "\n",
    "\n",
    "上記の処理を系列数n_sequences回繰り返すことになります。RNN全体への入力$x$は(batch_size, n_sequences, n_features)のような配列で渡されることになり、そこから各時刻の配列を取り出していきます。\n",
    "\n",
    "\n",
    "分類問題であれば、それぞれの時刻のhに対して全結合層とソフトマックス関数（またはシグモイド関数）を使用します。タスクによっては最後の時刻のhだけを使用することもあります。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 【問題2】小さな配列でのフォワードプロパゲーションの実験\n",
    "\n",
    "小さな配列でフォワードプロパゲーションを考えてみます。\n",
    "\n",
    "\n",
    "入力x、初期状態h、重みw_xとw_h、バイアスbを次のようにします。\n",
    "\n",
    "\n",
    "ここで配列xの軸はバッチサイズ、系列数、特徴量数の順番です。\n",
    "\n",
    "### まとめて以下で実装"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class SimpleRNN:\n",
    "    def _tanh(self, A):\n",
    "        Z = np.tanh(A)\n",
    "        return Z\n",
    "\n",
    "    def forward(self, x, w_x, w_h):\n",
    "        batch_size = x.shape[0] # 1\n",
    "        n_sequences = x.shape[1] # 3\n",
    "        # n_features = x.shape[2] # 2\n",
    "        n_nodes = w_x.shape[1] # 4\n",
    "        h = np.zeros((batch_size, n_nodes)) # (batch_size, n_nodes)\n",
    "        b = np.array([1, 1, 1, 1]) # (n_nodes,)\n",
    "\n",
    "        for i in range(n_sequences):\n",
    "            at = x[:,i,:] @ w_x + h @ w_h + b\n",
    "            h = self._tanh(at)\n",
    "        return h\n",
    "\n",
    "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size, n_sequences, n_features)\n",
    "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)\n",
    "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)\n",
    "\n",
    "myRNN = SimpleRNN()\n",
    "myRNN.forward(x, w_x, w_h)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# h = np.array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]]) # (batch_size, n_nodes)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 計算があってそうだけど答えが合わない\n",
    "# 後で要チェく"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('sub': conda)"
  },
  "interpreter": {
   "hash": "15fd5775daec78a3d2b557d938fb15a01a1c62fbdbfe50f040346c1054e408d2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}